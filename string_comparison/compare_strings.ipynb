{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Similarity Automation\n",
    "\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from scipy.special import softmax\n",
    "from connecting_db import connection\n",
    "from query_functions import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(str1: str, str2: str):\n",
    "\n",
    "    \"\"\"\n",
    "    This function adds zero padding to the left in the smallest string\n",
    "    \"\"\"\n",
    "\n",
    "    max_size = max(len(str1), len(str2))\n",
    "    return str1.zfill(max_size), str2.zfill(max_size)\n",
    "\n",
    "def truncate_strings(str1: str, str2: str, right_truncation: bool = True): \n",
    "\n",
    "    \"\"\"\n",
    "    This function truncates the longer string to meet the smaller string's size. \n",
    "    It can be truncated to the left or to the right.\n",
    "    \"\"\"\n",
    "    min_size = min(len(str1), len(str2))  \n",
    "\n",
    "    if right_truncation:\n",
    "\n",
    "        return str1[:min_size], str2[:min_size]\n",
    "    \n",
    "    else: \n",
    "        return str1[-min_size:], str2[-min_size:]\n",
    "\n",
    "        \n",
    "def get_id(str1: str, case_sensitive: bool = True, *args, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    This function converts the string to a numpy array composed of the ids from the characters\n",
    "    \n",
    "    \"\"\"\n",
    "    if not case_sensitive:\n",
    "        str1 = str1.upper()\n",
    "    \n",
    "    str1_array = np.array([ord(i) for i in str1])\n",
    "\n",
    "    return str1_array\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_strings(str1: str, str2: str, padding: bool = True, case_sensitive: bool = True, *args, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    This function compares both strings. Each character of both strings is compared with the character in the same position of the other string.\n",
    "\n",
    "    If the strings have different sizes:\n",
    "\n",
    "    padding = True -> We pad the smaller string with zeros to the left\n",
    "    padding = False -> We truncate the string to the left or to the right (right_truncation = True or False)\n",
    "\n",
    "    We can compare with case sensitive or not\n",
    "\n",
    "    case_sensitive = True or False \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if padding:\n",
    "        str1, str2 = add_padding(str1, str2, *args, **kwargs)\n",
    "    else:\n",
    "        str1, str2 = truncate_strings(str1, str2, *args, **kwargs)\n",
    "   \n",
    "    str1_id = get_id(str1, case_sensitive, *args, **kwargs)\n",
    "    str2_id = get_id(str2, case_sensitive, *args, **kwargs)\n",
    "\n",
    "    return np.mean(str1_id == str2_id)\n",
    "\n",
    "def is_contained(str1: str, str2: str, case_sensitive: bool = True):\n",
    "    \"\"\"\n",
    "    This function checks if the smaller string is contained in the bigger string\n",
    "    \n",
    "    \"\"\"\n",
    "    if not case_sensitive:\n",
    "        str1 = str1.upper()\n",
    "        str2 = str2.upper()\n",
    "\n",
    "    if str1 < str2:\n",
    "        return str1 in str2\n",
    "    else: \n",
    "        return str2 in str1\n",
    "\n",
    "def is_anagram(str1: str, str2: str, case_sensitive: bool = True, right_truncation: bool = True):\n",
    "\n",
    "    \"\"\"\n",
    "    This function checks if the strings are anagrams of each other.\n",
    "\n",
    "    The test can be case sensitive or not\n",
    "\n",
    "    If the strings have different sizes, it is possible to truncate the bigger one on the right or on the left side\n",
    "    \"\"\"\n",
    "\n",
    "    if not case_sensitive:\n",
    "        str1 = str1.upper()\n",
    "        str2 = str2.upper()\n",
    "\n",
    "    str1, str2 = truncate_strings(str1, str2, right_truncation=right_truncation)\n",
    "\n",
    "\n",
    "\n",
    "    str1_dict = Counter(str1)\n",
    "    str2_dict = Counter(str2)\n",
    "\n",
    "    return str1_dict == str2_dict\n",
    "\n",
    "def is_anagram_combined(str1: str, str2: str, case_sensitive: bool = True):\n",
    "\n",
    "    \"\"\"\n",
    "    This function combines the test truncating the bigger string in the right and the left.\n",
    "\n",
    "    The result is an OR of both results since we want to know if it is an anagram in any way.\n",
    "    \"\"\"\n",
    "\n",
    "    right_truncated = is_anagram(str1, str2, case_sensitive, right_truncation=True )\n",
    "    left_truncated = is_anagram(str1, str2, case_sensitive, right_truncation=False )\n",
    "\n",
    "    return right_truncated or left_truncated\n",
    "\n",
    "\n",
    "def log_difference(str1: str, str2: str,  padding: bool = True, case_sensitive: bool = True, *args, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    This function calculates the euclidian distance of the words using the ASCII table as a reference.\n",
    "\n",
    "    For example, the letter a from letter b are 1 unit apart. That means, the word 'ab' is sqrt((2-1)^2 + (3-2)^2) units apart from the word 'bc'\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if padding:\n",
    "\n",
    "        size_difference = abs(len(str1) - len(str2))\n",
    "        concat_array = np.zeros(size_difference)\n",
    "\n",
    "        str1_id = get_id(str1, case_sensitive, *args, **kwargs)\n",
    "        str2_id = get_id(str2, case_sensitive, *args, **kwargs)\n",
    " \n",
    "\n",
    "        if len(str1_id)>len(str2_id):\n",
    "            str2_id = np.concatenate((str2_id, concat_array))\n",
    "\n",
    "        elif len(str1_id)<len(str2_id):\n",
    "            str1_id = np.concatenate((str1_id, concat_array))\n",
    "\n",
    "\n",
    "    else:\n",
    "        str1, str2 = truncate_strings(str1, str2, *args, **kwargs)\n",
    "   \n",
    "        str1_id = get_id(str1, case_sensitive, *args, **kwargs)\n",
    "        str2_id = get_id(str2, case_sensitive, *args, **kwargs)\n",
    "        \n",
    "    difference = np.linalg.norm(str1_id- str2_id)\n",
    "  \n",
    "\n",
    "    if difference != 0:\n",
    "        return np.log(difference)\n",
    "    else:\n",
    "        return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_difference_combined(str1: str, str2: str, case_sensitive: bool = True):\n",
    "\n",
    "    \"\"\"\n",
    "    This function only combines all possible ways to measure the log distance, and returns a weighted average\n",
    "    \"\"\"\n",
    "\n",
    "    padding_pontuation = log_difference(str1, str2, padding=True,\n",
    "     case_sensitive=case_sensitive)\n",
    "    left_pontuation = log_difference(str1, str2, padding=False, case_sensitive=case_sensitive,right_truncation=False)\n",
    "    right_pontuation = log_difference(str1, str2, padding=False,case_sensitive=case_sensitive, right_truncation=True)\n",
    "    points = np.array([.5*padding_pontuation, .25*left_pontuation, .25*right_pontuation])\n",
    "    return np.linalg.norm(points)\n",
    "\n",
    "def compare_strings_combined(str1: str, str2: str, case_sensitive: bool = True):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    This function combines all ways to compare strings\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    similiarity_padding = compare_strings(str1, str2, padding= True, case_sensitive=case_sensitive)\n",
    "    similiarity_right = compare_strings(str1, str2, padding= False, case_sensitive=case_sensitive, right_truncation=True)\n",
    "    similiarity_left = compare_strings(str1, str2, padding= False, case_sensitive=case_sensitive, right_truncation=False)\n",
    "    is_contained_ = is_contained(str1, str2, case_sensitive=case_sensitive)\n",
    "\n",
    "    # print([similiarity_padding,similiarity_right,similiarity_left, is_contained_])\n",
    "    return np.mean([similiarity_padding,similiarity_right,similiarity_left, is_contained_] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparsion_metrics(str1: str, str2: str, case_sensitive: bool = True):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    This function returns all metrics in one list. We input 2 strings and get all possible metrics for these two strings.\n",
    "\n",
    "    \"\"\"\n",
    "    return [compare_strings_combined(str1, str2, case_sensitive), log_difference_combined(str1, str2, case_sensitive), is_anagram_combined(str1, str2)*1]\n",
    "    # return [compare_strings_combined(str1, str2, case_sensitive), log_difference(str1, str2, case_sensitive), is_anagram_combined(str1, str2)*1]\n",
    "\n",
    "def search_similar(str1: str, search_list: list, case_sensitive: bool = True):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    This function runs through a list of strings to compare with the targeted strings and returns the most similar string in the list for the metrics used.\n",
    "\n",
    "    It is useful to search for a similar string in a database of strings.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    similarities = np.array([comparsion_metrics(str1, str2, case_sensitive) for str2 in search_list])\n",
    "    most_similar_points = round(similarities[:, 0].max(),4)\n",
    "    most_similar_coordinates = similarities[:, 0].argmax()\n",
    "    closest_points = round(similarities[:, 1].min(),4)\n",
    "    closest_coordinates = similarities[:, 1].argmin()\n",
    "\n",
    "    anagram_max = similarities[:,2].max()\n",
    "    anagram_max_coordinates = similarities[:,2].argmax()\n",
    "\n",
    "    if anagram_max == 0:\n",
    "        anagram_serial = None\n",
    "    else:\n",
    "        anagram_serial = search_list[anagram_max_coordinates]\n",
    "        \n",
    "\n",
    "    return [most_similar_points, search_list[most_similar_coordinates], closest_points, search_list[closest_coordinates], anagram_serial]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize String Functions\n",
    "\n",
    "Functions to randomize strings. Used to cover confidential information during tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "sysrand = secrets.SystemRandom()\n",
    "\n",
    "def shuffle_string(str_: str, add_characters: bool = False, add_characters_byte_size: int = 1):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    This function shuffles the strings into a new string. It is also possible to add characters to make the strings even more different than the original ones\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    shuffle_string = str_\n",
    "\n",
    "    if add_characters:\n",
    "        shuffle_string =shuffle_string + secrets.token_hex(add_characters_byte_size).upper()\n",
    "    \n",
    "    shuffle_string = list(shuffle_string)\n",
    "    sysrand.shuffle(shuffle_string)\n",
    "\n",
    "    shuffle_string = ''.join(shuffle_string)\n",
    "    return shuffle_string\n",
    "\n",
    "def random_shuffle(str_: str):\n",
    "\n",
    "    \"\"\"\n",
    " This function randomizes strings in three different random ways:\n",
    "\n",
    "        1. Shuffles the original string\n",
    "        2. Shuffles and add characters to the original string\n",
    "        3. Adds new characters to the original string\n",
    "    \"\"\"\n",
    "    random_flag = sysrand.randint(1,3)\n",
    "    \n",
    "    if random_flag == 1:\n",
    "        str_ = shuffle_string(str_)\n",
    "    elif random_flag == 2:\n",
    "        str_ = shuffle_string(str_, add_characters= True)\n",
    "    else:\n",
    "        str_ = str_ + secrets.token_hex(1).upper()\n",
    "    \n",
    "    return str_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing strings\n",
    "\n",
    "### Reading the base data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlyte_query = read_query_file('./query_files/query_maximo_nlyte.sql')\n",
    "\n",
    "nlyte_assets = pd.read_sql_query(nlyte_query, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing blanks and void serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlyte_assets.SerialNumber.fillna('nan', inplace=True)\n",
    "nlyte_assets.SerialNumber.replace({ '': 'nan'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the algorithm in a small sample in the same database using anonymized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_serial</th>\n",
       "      <th>similarity_percentage</th>\n",
       "      <th>most_similar</th>\n",
       "      <th>log_distance</th>\n",
       "      <th>closeest</th>\n",
       "      <th>anagram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B3112DP1964004E5</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>BW074T5</td>\n",
       "      <td>2.2559</td>\n",
       "      <td>60H022T411310209</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25CCQNM</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>2541457</td>\n",
       "      <td>1.8139</td>\n",
       "      <td>728GPCD</td>\n",
       "      <td>NCQ5C2M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833NEAA0TC6YC25</td>\n",
       "      <td>0.1738</td>\n",
       "      <td>NCQ5C2M</td>\n",
       "      <td>2.5288</td>\n",
       "      <td>ER1T21BRH.2MO00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Q618KHBR</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>61ZNHP2</td>\n",
       "      <td>2.1782</td>\n",
       "      <td>7821HCNBD</td>\n",
       "      <td>R8B1H1KQ6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2517A445</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>50C17651P</td>\n",
       "      <td>1.6781</td>\n",
       "      <td>782478325</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>50E879278</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>50C17651P</td>\n",
       "      <td>1.5539</td>\n",
       "      <td>50B79826D</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>92QWGVTKPEB</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>92QWGVTKP</td>\n",
       "      <td>2.3976</td>\n",
       "      <td>61RF2LJ1C01</td>\n",
       "      <td>92QWGVTKP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>7701002101A407</td>\n",
       "      <td>0.5774</td>\n",
       "      <td>7701002101A4</td>\n",
       "      <td>2.1166</td>\n",
       "      <td>18000207F0052C</td>\n",
       "      <td>7701002101A4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0078082Z2FAF</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0078082Z2F</td>\n",
       "      <td>2.1132</td>\n",
       "      <td>80B547CN19GR</td>\n",
       "      <td>0078082Z2F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>41MJ168AB1L1X50</td>\n",
       "      <td>0.5359</td>\n",
       "      <td>41MJ168AB1L1X</td>\n",
       "      <td>2.3836</td>\n",
       "      <td>41MJ168AB1L1X</td>\n",
       "      <td>41MJ168AB1L1X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_serial  similarity_percentage   most_similar  log_distance  \\\n",
       "0    B3112DP1964004E5                 0.1897        BW074T5        2.2559   \n",
       "1             25CCQNM                 0.2143        2541457        1.8139   \n",
       "2     833NEAA0TC6YC25                 0.1738        NCQ5C2M        2.5288   \n",
       "3           1Q618KHBR                 0.1905        61ZNHP2        2.1782   \n",
       "4           A2517A445                 0.1667      50C17651P        1.6781   \n",
       "..                ...                    ...            ...           ...   \n",
       "245         50E879278                 0.2500      50C17651P        1.5539   \n",
       "246       92QWGVTKPEB                 0.5000      92QWGVTKP        2.3976   \n",
       "247    7701002101A407                 0.5774   7701002101A4        2.1166   \n",
       "248      0078082Z2FAF                 0.6792     0078082Z2F        2.1132   \n",
       "249   41MJ168AB1L1X50                 0.5359  41MJ168AB1L1X        2.3836   \n",
       "\n",
       "             closeest        anagram  \n",
       "0    60H022T411310209           None  \n",
       "1             728GPCD        NCQ5C2M  \n",
       "2     ER1T21BRH.2MO00           None  \n",
       "3           7821HCNBD      R8B1H1KQ6  \n",
       "4           782478325           None  \n",
       "..                ...            ...  \n",
       "245         50B79826D           None  \n",
       "246       61RF2LJ1C01      92QWGVTKP  \n",
       "247    18000207F0052C   7701002101A4  \n",
       "248      80B547CN19GR     0078082Z2F  \n",
       "249     41MJ168AB1L1X  41MJ168AB1L1X  \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 250\n",
    "a = []\n",
    "search_list = nlyte_assets.SerialNumber.sample(sample_size).tolist()\n",
    "\n",
    "search_list = [random_shuffle(i) for i in search_list] ## Making new random serial numbers to hide original ones\n",
    "new_sample = [random_shuffle(i) for i in search_list] ## Derivating a test list from the original\n",
    "# new_sample = nlyte_assets.SerialNumber.sample(sample_size).tolist()\n",
    "for i in new_sample:\n",
    "    a.append([i] + search_similar(i, search_list, False))\n",
    "pd.DataFrame(a, columns=['original_serial',\n",
    "                         'similarity_percentage', \n",
    "                         'most_similar', \n",
    "                         'log_distance', \n",
    "                         'closeest', 'anagram'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the database where the similarities are going to be searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv =  False\n",
    "\n",
    "file_name = 'MAXIMO_SHARED'\n",
    "\n",
    "\n",
    "columns_to_keep = ['ASSET_NUMBER',\n",
    "                    'CUSTOMER',\n",
    "                    'ASSET_STATUS',\n",
    "                    'MODEL',\n",
    "                    'REFERENCE_SERIAL_NUMBER',\n",
    "                    'CITY',\n",
    "                    'ROOM',\n",
    "                    'RACK',\n",
    "                    'KVA',\n",
    "                    'HW_ELIGIBLE_BY_NLYTE',\n",
    "                    'HW_NLYTE_HISTORY',\n",
    "                    'HW_NLYTE_LASTSCAN',\n",
    "                    'HW_NLYTE_UPDATE',\n",
    "                    'HW_MATERIAL_NAME',]\n",
    "if csv:\n",
    "    maximo = pd.read_excel(f'./{file_name}.xlsx', sheet_name=\"Sheet1\")\n",
    "    maximo = maximo.loc[:, columns_to_keep]\n",
    "    maximo.to_pickle(f'{file_name}.pkl.gz')\n",
    "else:\n",
    "    maximo = pd.read_pickle(f'{file_name}.pkl.gz')\n",
    "\n",
    "maximo = maximo.loc[:, columns_to_keep]\n",
    "maximo.REFERENCE_SERIAL_NUMBER = maximo.REFERENCE_SERIAL_NUMBER.apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Removing blanks and void serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximo.REFERENCE_SERIAL_NUMBER.fillna('nan', inplace=True)\n",
    "maximo.REFERENCE_SERIAL_NUMBER.replace({'': 'nan'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering only the clients where there was a scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = set(maximo[maximo.HW_NLYTE_LASTSCAN.notna() & maximo.HW_NLYTE_LASTSCAN.notnull()].CUSTOMER.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlyte_inventory = maximo.query('ASSET_STATUS == \"NLYTE INVENTORY\" and CUSTOMER.isin(@clients)').REFERENCE_SERIAL_NUMBER.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_updated = maximo.query('HW_ELIGIBLE_BY_NLYTE == \"Y\" and HW_NLYTE_UPDATE.isna() and CUSTOMER.isin(@clients) and REFERENCE_SERIAL_NUMBER != \"C\"').REFERENCE_SERIAL_NUMBER.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the database for similarities and saving into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = []\n",
    "for asset in nlyte_inventory:\n",
    "    assets.append([asset] + search_similar(asset, not_updated, False))\n",
    "\n",
    "df = pd.DataFrame(assets, columns=['original_serial',\n",
    "                         'similarity_percentage', \n",
    "                         'most_similar', \n",
    "                         'log_distance', \n",
    "                         'closeest', 'anagram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(assets, columns=['original_serial',\n",
    "                         'similarity_percentage', \n",
    "                         'most_similar', \n",
    "                         'log_distance', \n",
    "                         'closeest', 'anagram']).to_excel('comparsion.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0c70a28a227543aad0504f3c554e6fac9e03c6a937febfc79bbf97c251c03d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
